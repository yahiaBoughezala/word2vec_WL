######################################
# Hadoop configuraton
######################################
nameNode=hdfs://10.1.1.8:9000
jobTracker=10.1.1.8:8032

######################################
# oozie configuraton.coordinator not need oozie.wf.application.path configuration
######################################
queueName=default
oozieRoot=oozie
#DATE=20170720
######################################
# define ssh and configuration
######################################

dataSourceExecutionHost=10.1.1.8
dataSourceScriptFile=/home/hadoop/apps/spark-word2vec-datasource/bin/loadRawNewsFromDB2Json.sh

sampleExecutionHost=10.1.1.8
samplingScriptFile=/home/hadoop/apps/multiDirectoryWord2VecSampling/bin/multiDirectoryWord2VecSampling.sh

trainingExecutionHost=10.1.1.8
trainingScriptFile=/home/hadoop/apps/spark-NewsWord2Vec/bin/start.sh

#oozie.wf.application.path=hdfs://10.1.1.8:9000/user/hadoop/oozie/apps/caishi/word2vec


######################################
#coordinator configuration
######################################
oozie.coord.application.path=hdfs://10.1.1.8:9000/user/hadoop/oozie/apps/caishi/word2vec
start=2017-07-20T13:55+0800
end=2099-12-31T08:00+0800
workflowAppUri=hdfs://10.1.1.8:9000/user/hadoop/oozie/apps/caishi/word2vec